 有5百万的数据，一部分是算法合成，另外20%的数据是真实数据
对你的训练数据进行一些简单的图像处理，比如0-1化，然后再放入模型中，这样可能会更准确。或者对预测的结果，在ctc解码的前一步进行阀值过滤

 OCR模型训练在crnn.pytorch上进行了优化，实现了不定长图片的训练（现实生活不可能存在绝对的定长），或者你可以保持每一个batch是定长的；训练、预测都会对图像进行resize操作，图像的高处理为32像素，训练集大概几百万

由于CNN需要输入图片缩放到一个固定size，以满足固定的输入维度，不适合变长的序列化目标识别。在CRNN中，我们将deep features转成顺序表示，以便能表示不同长度的序列化目标

crnn.pytorch 训练中文，要修改部分代码。不同batch可以不同，但是同一个batch的大小肯定需要一样

训练中文的话，你可以采用ImgW=256或者512，实际训练图像不足512

训练集最好是具有语义信息，如果只是将文字随机的组合生成图片作为训练集，模型收敛会更慢并且准确率受限

需要准备 1.自己的数据集 2.自己数据集基于的词典

定数据集的背景和字体类似

crnn 训练语料里加入空格一起训练就可以输出空格了

loss小的时候可以先保存模型，用小的学习率学习

运用一些商业（比如百度、讯飞）API识别的结果，与自己训练构造数据集的结果对比，如果结果一致，默认识别结果有效

训练集加入尺寸比较小的图片，训练时再resize成w=32，h按比例放大
生成字体较小的280*32大小的图片

模型根据自己的识别场景利用数据集finetune

避免‘0oO’这样的字符在同一行

dense ocr 选择SGD要好一些，lstm ocr 选择adadelta(lr=0.1,收敛到小范围后，再调小一些)

YOLOv3训练过程和ctpn类似，现检测最小box，然后按行进行聚类

yolo文字训练和其他对象检测训练方式类似，唯一不同的是，后续有一个box聚类，原理参考了ctpn相关代码。此项目标注了“text”,'None'（无用,只是在于增加一个分类，实际中没有用的none），的目的在于如果只训练一个分类，yolo3无法收敛

yolo文字检测训练代码很简单哈，训练完全是按照darknet训练方式训练，也可以用https://github.com/qqwweee/keras-yolo3.git
还有很多地方需要优化，比如anchors,后面优化了，会一起放出来哈。box聚类代码在detector目录中

识别分隔比较开的字,优化:调整model函数中alph参数即可，默认是0.1，可设置大一点

常规字体,提高识别率:MAX_HORIZONTAL_GAP调节大一点

优化：
第一种，根据识别的部分字符，去做二次检测，例如识别出“单选”字符，那么根据此字符串的坐标，修改此坐标的w为图像的width，然后再调用OCR识别此行即可，或者直接将model.py文件中alph=0.2，alph设置为足够大，比如500。
第二种，修改相关参数，详见（detectors.py）文件，修改MIN_RATIO（字符width/height），默认为1，手动调整为你检测图像集的最优值；TEXT_PROPOSALS_WIDTH(最小字符宽度)，默认是5， 可以调为0.

标准的一行一行的识别，其实可以不用yolo3进行文字定位，直接采用传统的分割，就可以得到每一行，然后调用OCR

0-1处理的方式进行行分割的时候（先切除图像边缘，边缘噪声可能很大，比如切掉10%的边缘），如果图像文字倾斜太大，应先进行文字方向校正，要做一些后处理，比如行高度过小，应该就舍弃，行高度太大，就切分。识别的时候，要根据坐标取原图的图像。这样的话，准确率可能提高很多。

ou should train more than 4000 iterations before you will check accuracy

chineseocr使用今年新出的通用目标检测系统YOLOv3进行文本检测，使用华中科技大学白翔老师团队2015年的结合了CNN, RNN 与 CTC loss 的CRNN文本序列识别方案

识别空格效果不会很好，loss一直在2～3之间剧烈震荡，去掉空格后能收敛到0.2以下。另外一种更好的方式，将整个单词考虑成一个，而不是去识别单词中的每个字母，构造你训练集的词袋即可，这样也能收敛。
